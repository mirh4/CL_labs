{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drMutSkQCmDF"
      },
      "source": [
        "**Лабораторная работа 3. Определение тематики подборки текстов**\n",
        "\n",
        "Лабораторная работа №3 посвящена решению задачи определения тематики текстов с помощью построения списка ключевых слов. Нормативное время выполнения работы 4 академических часа.\n",
        "\n",
        "**Инструкция.** Создайте копию блокнота, где в качестве имени файла указаны номер работы и ФИО студента (например, `3_Иванов_ИО.ipynb`). В созданном файле решите предложенные задачи. Затем сдайте работу преподавателю (расшарьте блокнот и сдайте готовую работу через MS Teams).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ijQP9NUyC3HU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd5fc0b1-9616-4b60-ab58-a4906f9d09bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XF-4k4SesWt"
      },
      "source": [
        "**Задание** В файле `data.csv` содержится подборка из тысячи постов социальных сетей, являющаяся частью результата выполнения поискового запроса по некоторой тематике, собранных системой мониторинга «Крибрум». Ваша задача состоит определении тематики этой подборки.\n",
        "\n",
        "Для упрощения решения задачи ниже приведены примерные этапы алгоритма. Вам необходимо написать реализацию этого алгоритма и ответить на итоговый вопрос.\n",
        "\n",
        "Алгоритм кратко:\n",
        "1.\tЗагрузить нужные данные из файла в словарь.\n",
        "2.  Для каждого элемента этого словаря:\n",
        "    1.  Перевести в строковый тип данных.\n",
        "    2.  Привести к нижнему регистру.\n",
        "    3.\tУдалить пунктуацию, ссылки, концы строк, слова на английском и прочие нерелевантные символы.\n",
        "    4.  Склеить полученную строку с основным текстом.\n",
        "    После завершения цикла у вас должен получиться единый текст, содержащий слова, разделенные только пробельными символами.\n",
        "3.\tВыполнить лемматизацию (привести все слова в их начальную словоформу).\n",
        "4.  Удалить из полученного текста стоп-слова.\n",
        "5.  Сформировать словарь, где ключом будет слово, а значением — количество его вхождений в текст.\n",
        "6.  Отсортировать слова по частоте их употребления и выделить 100 наиболее употребимых слов. Записать его в файл.\n",
        "7.  На основе полученного списка слов сделать вывод о тематике подборки текстов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGF2bPE4epRH"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcVUULhoe1NR"
      },
      "source": [
        "Загрузите данные из файла `data.csv` (разделитель `;`). Определите, какой именно столбец потребуются для решения задачи, и загрузите в датафрейм только его.\n",
        "\n",
        "**Примечание:** файл представляет собой подборку реальных данных и, как многие реальные данные, содержит ошибки. Если считывать его как файл с разделителем `,`, ошибки помещают обработке. Можно, конечно, попробовать найти их и исправить, но на практике часто проще выделить нужную часть данных автоматически."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9mYzx5Hle5Ct"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ML_course/data.csv', sep=';')\n",
        "df.head()\n",
        "df=df['url,author,type,parent_post_url,tag,body']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjOFnPsbe5q9"
      },
      "source": [
        "Преобразуйте данные в словарь (выполните следующую ячейку)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rtb1tVgfe7Ad"
      },
      "outputs": [],
      "source": [
        "Dictionary=df.to_dict()\n",
        "Dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZfbSmMIe7v9"
      },
      "source": [
        "Выполните пункт 2 описанного выше алгоритма (ряд преобразований для каждого элемента полученного словаря). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "XrwtMsDxe8Ut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14eacff-cdeb-418b-ba1b-3ee140874005"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# В конце ячейки назовите переменную, в которой будет храниться полный очищенный текст, allText\n",
        "# Переменная allText должна иметь тип данных список, поэтому, если она имеет текстовый формат, \n",
        "# в конце ячейки необходимо выполнить следующий код\n",
        "import re\n",
        "allText = str(Dictionary)\n",
        "allText = allText.casefold()\n",
        "allText = re.sub(r'[^а-яА-ЯёЁ]',' ', allText)\n",
        "allText = allText.split()\n",
        "print(allText)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QOZ2lRte80M"
      },
      "source": [
        "Для выполнения пунктов 3 и 4 потребуется запустить следующий код. Постарайтесь понять, как он работает.\n",
        "\n",
        "Следующая команда устанавливает модуль специализированного назначения, предназначенный для работы с текстовой информацией.  Если вы работаете в Anaconda, модуль достаточно установить однократно, после чего он будет доступен из других программ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "A49jeg4_H6vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2192fa2b-a75a-4c1f-c74d-5342f4802e4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.8/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.8/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pymorphy2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCqjj6Iqe9-t"
      },
      "source": [
        "Загрузим морфологический анализатор и стоп-слова.\n",
        "\n",
        "Стоп-слова ([Шумовые слова](https://ru.wikipedia.org/wiki/%D0%A8%D1%83%D0%BC%D0%BE%D0%B2%D1%8B%D0%B5_%D1%81%D0%BB%D0%BE%D0%B2%D0%B0), мусорные слова) — слова, которые не нужно учитывать в поисковых запросах. Они употребляются достаточно часто и при этом не являются определяющими для тематики текста. Перед анализом нужно удалить стоп-слова из текста. Здесь мы подключаем общие стоп-слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "WYTm6rfEe-pL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d332d664-b1d4-4b15-cf36-b2b253967c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Импортируем установленный модуль для выполнения лемматизации\n",
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "# Импортируем nltk из установленного пакета. Это нужно для получения списка стоп-слов\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "rus_stops = set(stopwords.words('russian'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9P3dMgae_H8"
      },
      "source": [
        "Дополняем список стоп-слов. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6GqWWLmIJklW"
      },
      "outputs": [],
      "source": [
        "myStopWords=['что-то', 'это', 'который', 'наш', 'свой', 'ваш', 'такой', 'весь', 'один', 'другой', 'самый', 'каждый', 'очень', 'тот', 'просто', 'мой', 'мы', 'также', 'сам', 'пока', 'социальный', 'сети']\n",
        "myStops=set(myStopWords)\n",
        "rus_stops = rus_stops|myStops\n",
        "\n",
        "allText=[i for i in allText if i not in rus_stops]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j11Y392mJ0z8"
      },
      "source": [
        "Выполняем лемматизацию и удаляем стоп-слова.\n",
        "\n",
        "Лемматизация — это процесс приведения слова к его начальной форме. Для существительного это именительный падеж единственного (иногда множественного) числа, для глагола инфинитив и т.д.\n",
        "\n",
        "Выполнение следующей ячейки может занять некоторое время."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ZxrdwemJJp5g"
      },
      "outputs": [],
      "source": [
        "# Функция для лемматизации\n",
        "def lemmatize(allText):\n",
        "    res = list()\n",
        "    for word in allText:\n",
        "        p = morph.parse(word)[0]\n",
        "        res.append(p.normal_form)\n",
        "    return res\n",
        "# Лемматизация (пункт 3 алгоритма)\n",
        "allText=lemmatize(allText)\n",
        "# Удаление стоп-слов (пункт 4 алгоритма)\n",
        "allText=[i for i in allText if i not in rus_stops]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT8hdDxQLD_o"
      },
      "source": [
        "Выполните пункт 5 алгоритма."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "o5u7VjpLLPfp"
      },
      "outputs": [],
      "source": [
        "slovar = {}\n",
        "\n",
        "for n in allText:\n",
        "    if n in slovar:\n",
        "        slovar[n] += 1\n",
        "    else:\n",
        "        slovar[n] = 1\n",
        "\n",
        "# for x,y in slovar.items():\n",
        "#     print(x, '=',y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtH9lxOqLQF2"
      },
      "source": [
        "Выполните пункт 6 алгоритма."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "wT2qj5nvLQkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd536f09-1ab1-45a7-c496-1aa47264063e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('человек', 1013), ('год', 1004), ('день', 916), ('благотворительный', 798), ('ребёнок', 662), ('помощь', 620), ('жизнь', 518), ('показать', 512), ('полностью', 494), ('время', 480), ('деньга', 427), ('добрый', 413), ('стать', 410), ('дело', 391), ('фонд', 380), ('помочь', 362), ('друг', 358), ('мочь', 340), ('доброта', 336), ('новый', 335), ('дом', 308), ('проект', 305), ('семья', 302), ('должный', 301), ('благотворительность', 300), ('работа', 300), ('россия', 293), ('делать', 287), ('мир', 287), ('первый', 285), ('г', 283), ('сделать', 271), ('организация', 268), ('нужно', 253), ('праздник', 247), ('февраль', 236), ('говорить', 233), ('хотеть', 231), ('сегодня', 227), ('иметь', 226), ('дать', 224), ('сказать', 222), ('хороший', 220), ('группа', 220), ('слово', 220), ('участие', 217), ('спасибо', 217), ('сбор', 216), ('помогать', 213), ('пара', 209), ('город', 202), ('место', 196), ('рубль', 195), ('сумма', 194), ('любой', 191), ('мероприятие', 187), ('нужный', 187), ('получить', 180), ('средство', 179), ('март', 176), ('добро', 174), ('работать', 174), ('знать', 173), ('женщина', 171), ('проявление', 170), ('вопрос', 169), ('пройти', 167), ('давать', 166), ('карта', 166), ('поддержка', 164), ('возможность', 164), ('несколько', 162), ('сила', 158), ('счёт', 158), ('право', 156), ('огромный', 154), ('принять', 153), ('жить', 153), ('вещь', 151), ('история', 150), ('любовь', 149), ('страна', 149), ('мама', 147), ('международный', 147), ('волонтёр', 146), ('животное', 144), ('проблема', 142), ('центр', 141), ('больший', 141), ('заниматься', 141), ('являться', 140), ('спонтанный', 140), ('часть', 139), ('известный', 138), ('цель', 136), ('дорога', 135), ('родитель', 134), ('вместе', 134), ('область', 134), ('рука', 133)]\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "\n",
        "c = collections.Counter(slovar)\n",
        "\n",
        "print(c.most_common(100))\n",
        "c = c.most_common(100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "conv_slov = dict(c)\n",
        "\n",
        "for x,y in conv_slov.items():\n",
        "     print(x, '=',y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxBJf7DdwlRF",
        "outputId": "bb3434bd-b99c-4a55-9cd2-537e79d07d26"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "человек = 1013\n",
            "год = 1004\n",
            "день = 916\n",
            "благотворительный = 798\n",
            "ребёнок = 662\n",
            "помощь = 620\n",
            "жизнь = 518\n",
            "показать = 512\n",
            "полностью = 494\n",
            "время = 480\n",
            "деньга = 427\n",
            "добрый = 413\n",
            "стать = 410\n",
            "дело = 391\n",
            "фонд = 380\n",
            "помочь = 362\n",
            "друг = 358\n",
            "мочь = 340\n",
            "доброта = 336\n",
            "новый = 335\n",
            "дом = 308\n",
            "проект = 305\n",
            "семья = 302\n",
            "должный = 301\n",
            "благотворительность = 300\n",
            "работа = 300\n",
            "россия = 293\n",
            "делать = 287\n",
            "мир = 287\n",
            "первый = 285\n",
            "г = 283\n",
            "сделать = 271\n",
            "организация = 268\n",
            "нужно = 253\n",
            "праздник = 247\n",
            "февраль = 236\n",
            "говорить = 233\n",
            "хотеть = 231\n",
            "сегодня = 227\n",
            "иметь = 226\n",
            "дать = 224\n",
            "сказать = 222\n",
            "хороший = 220\n",
            "группа = 220\n",
            "слово = 220\n",
            "участие = 217\n",
            "спасибо = 217\n",
            "сбор = 216\n",
            "помогать = 213\n",
            "пара = 209\n",
            "город = 202\n",
            "место = 196\n",
            "рубль = 195\n",
            "сумма = 194\n",
            "любой = 191\n",
            "мероприятие = 187\n",
            "нужный = 187\n",
            "получить = 180\n",
            "средство = 179\n",
            "март = 176\n",
            "добро = 174\n",
            "работать = 174\n",
            "знать = 173\n",
            "женщина = 171\n",
            "проявление = 170\n",
            "вопрос = 169\n",
            "пройти = 167\n",
            "давать = 166\n",
            "карта = 166\n",
            "поддержка = 164\n",
            "возможность = 164\n",
            "несколько = 162\n",
            "сила = 158\n",
            "счёт = 158\n",
            "право = 156\n",
            "огромный = 154\n",
            "принять = 153\n",
            "жить = 153\n",
            "вещь = 151\n",
            "история = 150\n",
            "любовь = 149\n",
            "страна = 149\n",
            "мама = 147\n",
            "международный = 147\n",
            "волонтёр = 146\n",
            "животное = 144\n",
            "проблема = 142\n",
            "центр = 141\n",
            "больший = 141\n",
            "заниматься = 141\n",
            "являться = 140\n",
            "спонтанный = 140\n",
            "часть = 139\n",
            "известный = 138\n",
            "цель = 136\n",
            "дорога = 135\n",
            "родитель = 134\n",
            "вместе = 134\n",
            "область = 134\n",
            "рука = 133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9uVfqMULXuu"
      },
      "source": [
        "Проанализируйте полученный файл и напишите ниже содержательный вывод о тематике подборки текстов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFiNE5KLE60I"
      },
      "source": [
        "Самым часто встречаемым словом в словаре является \"Человек\", что связано с частым употреблением этого слова в целом.  Данное слово имеет нейтральную коннотацию и не позволяет определить тематики подборки текстов.\n",
        "\n",
        "Однако иные наиболее популярные слова, такие как \"Благотворительный, ребенок, помощь, жизнь, фонд, помочь\" позволяют установить что тематики подборки текстов в первую очередь связана с благотворительной деятельностью и работой благотворительных фондов для помощи детям.\n",
        "\n",
        "Такие часто встречаемые слова \"спонтанный, волонтер, давать, поддержка, средство, участие\" можно связать с тем что в данных текстах людей призывают учавствовать в благотворительной деяетельности\n",
        "\n",
        "Также в связи с частой встречаемостью таких слов как \"Дом, Россия, область\" можно утверждать что работа данных фондов осуществляется в нашей стране, а такие часто встречаемые слова как \"феваль, март\" позволяют определить время того когда будет данная активность\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JOUgEcipkssX"
      },
      "execution_count": 56,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}